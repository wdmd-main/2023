import{U as v,ab as h,V as p,W as u,E as m,$ as o,a8 as r,a4 as l,F as i,al as g,an as y,a5 as b,_ as E,ap as I,a$ as S,b0 as s,a9 as n,a3 as c}from"./index-ca778e8e.js";const w=v({direction:{type:String,values:["horizontal","vertical"],default:"horizontal"},contentPosition:{type:String,values:["left","center","right"],default:"center"},borderStyle:{type:h(String),default:"solid"}}),k=p({name:"ElDivider"}),A=p({...k,props:w,setup(d){const e=d,t=u("divider"),f=m(()=>t.cssVar({"border-style":e.borderStyle}));return(a,H)=>(o(),r("div",{class:l([i(t).b(),i(t).m(a.direction)]),style:b(i(f)),role:"separator"},[a.$slots.default&&a.direction!=="vertical"?(o(),r("div",{key:0,class:l([i(t).e("text"),i(t).is(a.contentPosition)])},[g(a.$slots,"default")],2)):y("v-if",!0)],6))}});var T=E(A,[["__file","divider.vue"]]);const C=I(T);const _={},D={class:"keynote-speakers"};function R(d,e){const t=C;return o(),r("div",D,[e[0]||(e[0]=s('<div class="title1 font-merri" data-v-69fe2250>Keynote Speakers</div><div class="title2 section-title" data-v-69fe2250>Joseph Sifakis, Verimag</div><div class="content" data-v-69fe2250><div class="pa" data-v-69fe2250><p data-v-69fe2250><span class="bold" data-v-69fe2250>Keynote: </span><span data-v-69fe2250> Trustworthy Intelligent Systems – A Daunting Challenge</span></p></div><div class="pa" data-v-69fe2250><p data-v-69fe2250><span class="bold" data-v-69fe2250>Abstract: </span><span class="italic" data-v-69fe2250> Systems engineering today is torn between two contradictory trends. On the one hand, the construction of intelligent systems, capable of situation awareness and adaptive decision-making through the use of AI-based components; on the other, the need for trustworthiness guarantees despite the non-explicability of AI components. The situation is exacerbated by the need for increasingly complex and integrated heterogeneous systems, and by the fact that in the current debate on &quot;safe AI&quot;, key players in the field are promoting approaches that break with the technical safety concept of systems engineering.</span></p><p class="italic indent" data-v-69fe2250>We consider that a system is explainable if it is possible to characterize its relevant behavior by faithful models that lend themselves to analysis and provide a basis for understanding. We argue that AI will remain largely inexplicable. Ignoring this limitation by ascribing anthropomorphic properties to AI systems is technically untenable.</p><p class="italic indent" data-v-69fe2250>We need rigorous system design methodologies that integrate model-based and data-driven AI te chniques, enabling in particular the construction of reliable systems integrating unreliable AI components. These methodologies will be characterized by the following important changes: </p><ul data-v-69fe2250><li class="italic indent" data-v-69fe2250>Breaking with the idea that system can be guaranteed trustworthy at design time. Instead, systems must be designed to evolve, with no endpoint in their evolution, using computational intelligence, monitoring techniques and over-the-air upgrades.</li><li class="italic indent" data-v-69fe2250>A shift from verification to empirical validation using test and simulation, which in principle does not allow confidence levels achieved using model-based methods. </li><li class="italic indent" data-v-69fe2250>A better integration of design for dependability into the system development cycle, by jointly addressing safety and security issues, and relying heavily on automated tools.</li></ul><p class="italic indent" data-v-69fe2250>We advocate the need for a new foundation for system design that responds to these needs, leveraging knowledge management to compensate for weaknesses arising from the obsolescence of model-based techniques.</p></div><div data-v-69fe2250><p data-v-69fe2250><span class="bold" data-v-69fe2250>Bio: </span><span data-v-69fe2250> Professor Joseph Sifakis is Emeritus Research Director at Verimag. He has been a full professor at Ecole Polytechnique Fédérale de Lausanne (EPFL) for the period 2011-2016. He is the founder of the Verimag laboratory in Grenoble, a leading laboratory in the area of safety critical systems that he directed for 13 years.</span></p><p class="indent" data-v-69fe2250>Joseph Sifakis has made significant and internationally recognized contributions to the design of trustworthy systems in many application areas, including avionics and space systems, telecommunications, and production systems. His current research focuses on autonomous systems, in particular self-driving cars and autonomous telecommunication systems. In 2007, he received the Turing Award, recognized as the &quot;highest distinction in computer science&quot;, for his contribution to the theory and application of model checking, the most widely used system verification technique. </p><p class="indent" data-v-69fe2250>Joseph Sifakis is a member of six academies and a frequent speaker at international scientific, technical and public forums.</p></div></div>',3)),n(t),e[1]||(e[1]=s('<div class="title2 section-title" data-v-69fe2250>Zheng Zheng, Beihang University</div><div class="content" data-v-69fe2250><div class="pa" data-v-69fe2250><p data-v-69fe2250><span class="bold" data-v-69fe2250>Keynote: </span><span data-v-69fe2250> Reliability and Testing of Reinforcement Learning Systems</span></p></div><div class="pa" data-v-69fe2250><p data-v-69fe2250><span class="bold" data-v-69fe2250>Abstract: </span><span class="italic" data-v-69fe2250> As reinforcement learning (RL) systems proliferate across various domains, ensuring their reliability becomes crucial. This presentation provides a comprehensive examination of RL system reliability and testing, focusing on their unique characteristics. The topics include:</span></p><ul data-v-69fe2250><li class="italic indent" data-v-69fe2250>Analysis of reliability and testing attributes of RL systems.</li><li class="italic indent" data-v-69fe2250>Construction of metamorphic relations tailored for RL.</li><li class="italic indent" data-v-69fe2250>Introduction of coverage metrics specific to RL scenarios.</li><li class="italic indent" data-v-69fe2250>Methods for generating test cases for RL environments.</li></ul><p class="italic indent" data-v-69fe2250>The talk offers insights into the challenges and methodologies for validating and ensuring the robustness of reinforcement learning systems in diverse applications.</p></div><div data-v-69fe2250><p data-v-69fe2250><span class="bold" data-v-69fe2250>Bio: </span><span data-v-69fe2250> Zheng Zheng is a professor at Beihang University and the deputy dean of School of Automation Science and Electrical Engineering. His research work is primarily concerned with software reliability and testing. Recently, He paid more attention on the intelligent software reliability engineering. He is co-author of over 100 journal and conference publications, including IEEE TDSC, IEEE TIFS, IEEE TSE, IEEE TR, IEEE TSC, JSS and so on. He serves for IEEE PRDC2019, IEEE DASC 2019, IEEE ISSRE 2020, IEEE QRS 2021 as PC Co-Chairs, as well as WoSAR 2019, DeIS 2020 and DeIS 2021 as General Co-Chairs. He is Editor-in-chief of Atlantis Highlights in Engineering (Springer Nature), Associate Editor of IEEE TR (2021- ), Elsevier KBS (2018- ) and Springer IJCIS (2012- ) and Guest Editor of IEEE TDSC (2021). He is IEEE Senior Member and IEEE CIS Emerging Technologies TC member.</span></p></div></div>',2)),n(t),e[2]||(e[2]=s('<div class="title2 section-title" data-v-69fe2250>Domenico Cotrone, University of Naples Federico II</div><div class="content" data-v-69fe2250><div class="pa" data-v-69fe2250><p data-v-69fe2250><span class="bold" data-v-69fe2250>Keynote: </span><span data-v-69fe2250> Unveiling the Veil: Towards the Trustworthiness of AI Code Generators</span></p></div><div class="pa" data-v-69fe2250><p data-v-69fe2250><span class="bold" data-v-69fe2250>Abstract: </span><span class="italic" data-v-69fe2250> Nowadays, AI code generators have emerged as powerful tools transforming the software development landscape. These tools promise accelerated productivity and efficiency, but they also raise crucial questions regarding the trustworthiness of the code they produce. This keynote talk delves into the heart of this critical issue, aiming to provide a comprehensive understanding of the topics related to the trustworthiness of AI code generators, focusing on the security and robustness aspects of these AI-powered solutions.</span></p><p class="italic indent" data-v-69fe2250>Beginning with an in-depth examination of the security and robustness landscape surrounding AI code generators, the talk will dissect the common threats and risks associated with new technology impacting our everyday lives. From adversarial inputs to poisoning attacks, understanding these potential pitfalls is crucial for developers and organizations alike.</p></div><div data-v-69fe2250><p data-v-69fe2250><span class="bold" data-v-69fe2250>Bio: </span><span data-v-69fe2250> Domenico Cotroneo is a Full Professor at the Department of Electrical Engineering and Information Technology, University of Naples Federico II. He is also an IEEE Senior Member. He has served on the Technical Program Committee of important conferences on Dependability and Software Reliability, eg., IEEE/IFIP DSN, IEEE SRDS, Safecomp, IEEE ISSRE, and IEEE ICDS. Domenico’s research activities cover the following areas: dependability assessment of complex software systems, software fault injection, and software performance degradation analysis.</span></p></div></div>',2)),n(t),e[3]||(e[3]=c("div",{class:"title2 section-title"},"Ryan Cotterell, ETH Zürich",-1)),e[4]||(e[4]=c("p",{class:"pa-content p"},"TBD",-1))])}const q=S(_,[["render",R],["__scopeId","data-v-69fe2250"]]);export{q as default};
